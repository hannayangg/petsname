{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c671c4e1-4d28-4790-81eb-12fe688d9875",
   "metadata": {},
   "source": [
    "1단계는 데이터 준비야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ece333a-ab89-477e-9e51-29842cb2a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *  #untar_data쓰기 위해서 필요해.\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "#전체 데이터를 다운로드해. path 에는 전체 데이터의 경로들이 있어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ff3719-8f42-4bd9-88fc-0fd23364118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "#3과 7 학습데이터의 경로들을 빼둬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6644c341-e665-4192-b2f0-1f16eac043d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "#3과 7 학습데이터 경로를 열어서 텐서 형태로 담아둬.\n",
    "#리스트에는 6000개의 개별 텐서들이 담길 거야. len(seven_tensors)=6000이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d11f9d1-5d25-4002-bb47-b6de40fe7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "#개별 텐서들을 묶어서 하나의 텐서로 만든 후 255로 나눠서 0~1값으로 조정해.\n",
    "#stack을 하는 이유: 원래 2D텐서들이 묶여있는 ‘리스트’ 였는데, 이것을 하나의 ‘텐서’로 만드는거야. 그래서 결과적으로 3D텐서를 만드는거야. 리스트보다 텐서가 계산이 빠르니까. 모양은 같은데 리스트에서 텐서로 바뀐 거야.\n",
    "#stacked_sevens.shape=[6000,28,28]이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37eeab58-8478-4a75-aefd-445f1a63e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "#검증데이터에 대해서도 동일한 작업을 해.\n",
    "#valid_7_tens.shape=[1000,28,28]이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7d40ab-b584-4241-84a1-44ae6202c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "dset = list(zip(train_x, train_y))\n",
    "#입력데이터를 묶어주는 거야. 3과 7텐서를 묶어준 후 2D텐서로 형태를 바꿔줘.\n",
    "#train_x.shape=[1100,2828]이야.\n",
    "#정답데이터를 만들어줘. 입력과 동일하게 2D텐서 형태여야 해.\n",
    "#train_y.shape=[1100,1]이야.\n",
    "#그리고나서 입력과 정답데이터를 튜플 형태로 묶어준 것이 dset이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e15e0e1-7c5b-4b92-98bd-36c2ba3086db",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor ([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x, valid_y))\n",
    "#검증데이터에 대해서도 동일한 작업을 해.\n",
    "\n",
    "#len(dset), len(valid_dset) = (12396, 2038)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601377ea-75b4-464c-a2e9-bb3820578a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "#미니배치로 만들어 학습해야 효율적이야.\n",
    "#데이터셋에서 256개의 튜플을 무작위로 골라서 미니배치로 만들어.\n",
    "\n",
    "#len(dl),len(valid_dl) = (49, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14e272-f68e-4964-bacb-2d39a98724fc",
   "metadata": {},
   "source": [
    "2단계는 각종 함수를 만드는 거야.\n",
    "- 학습할 때 필요한 함수를 만들어.\n",
    "- 가중치추출함수, 모델 함수, 손실함수를 만들어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947910d9-075c-4716-b6a2-49aabeb88372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "#가중치를 추출하는 함수야. 이걸 이용해서 가중치와 편향을 선정할거야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f9524d2-5ec2-467a-8561-d7e4216c331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb):\n",
    "    return xb@weights + bias\n",
    "#모델 함수야. 입력데이터에 가중치를 곱하고 편향을 더한 값을 예측으로 리턴할거야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b222c28c-4c9c-4af0-baf3-caa86c8b9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "#손실 함수야. 예측값을 우선 0~1값으로 변형해줘.\n",
    "#예측값이 0.7이고 타겟이 1이라면 0.3의 손실값을 리턴하거야.\n",
    "#예측값이 0.7이고 타겟이 0이라면 0.7의 손실값을 리턴하거야."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9957f-e014-4a02-b340-b44122073750",
   "metadata": {},
   "source": [
    "3단계는 한 에포크 당 진행할 학습을 담은 함수를 만드는 거야.  \n",
    "1. 우선 파라미터의 기울기를 계산하고,  \n",
    "2. 파라미터에서 기울기와 학습률을 곱한 만큼을 빼주면서 파라미터를 업데이트 해야해.\n",
    "\n",
    "- x축이 파라미터를 나타내고 손실함수가 2차함수라고 가정하자. 국소 최솟값은 x=1일 때야.\n",
    "- 지금 파라미터x값이 2라면, 손실이 크고, 또 손실에 대한 기울기가 큰 상황이야.\n",
    "- 업데이트를 거치면서 x값이 점점 작아지고, 또 기울기도 점점 줄어들도록 만들어.\n",
    "- 결국 기울기가 작은 지점, 즉 손실 값이 가장 작아질 때까지 파라미터를 갱신하는 게 학습이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1130bf3b-b972-43c3-b485-213c08f8022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9684e92-47d0-4903-8a1b-2898c2f84010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, Ir, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "            \n",
    "#미니배치를 가지고 예측한 후, 손실에 대한 파라미터의 기울기를 구해.\n",
    "#그 기울기를 이용해서 파라미터를 업데이트해.\n",
    "#어차피 다음 미니배치를 가지고 calc_grad를 수행할 때 loss.backward로 기울기를 새로 구할 텐데 왜 초기화 해?\n",
    "#loss.backward는 기울기를 새로 구하는 게 아니라\n",
    "#방금전 앞서 계산된 기울기에 더하기 때문에 이전 기울기를 0으로 설정해줘야 해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286077b-c319-4508-8eff-b909226c113e",
   "metadata": {},
   "source": [
    "4단계는 정확도를 평가하는 함수를 만드는 거야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02013c7a-9c44-4448-9c9a-463c27d3f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "#한 배치 내에서 정답이면 1, 오답이면 0을 누적한 후 평균값을 리턴해. (0.7과 같은 숫자로 나와)\n",
    "\n",
    "#float() 하는 이유: 1, 0과 같은 정수는 mean()메서드를 쓸 수 없어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f1ab341-6bd1-4810-972d-e12f31b0829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "#검증데이터의 모든 배치의 정확도를 구한 후 평균값을 리턴해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b11c8-1ba4-42a7-8bcd-58436a384946",
   "metadata": {},
   "source": [
    "5단계는 학습을 진행하는 거야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "113833f0-01b3-49ca-be24-67fb7b365e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)\n",
    "params = weights, bias\n",
    "lr = 1.\n",
    "#파라미터를 추출하고, 학습률을 지정해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd37d246-384f-4f86-8253-f2ae7ae63418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6117 0.8427 0.9198 0.9457 0.9555 0.9603 0.9638 0.9657 0.9677 0.9686 0.9677 0.9681 0.9681 0.9696 0.9696 0.9706 0.9711 0.9711 0.9711 0.9711 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')\n",
    "#20회 에포크로 학습을 해. 즉, 전체 데이터셋을 20번 돌리며 학습해.\n",
    "#1에포크가 끝날 때마다 정확도를 출력해."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6dbba-ed21-403b-880d-5da72fe009d6",
   "metadata": {},
   "source": [
    "6단계는 옵티마이저 만들기야.\n",
    "- 옵티마이저 클래스에 학습률과 파라미터를 저장해.\n",
    "- 이건 파라미터를 “최적화”하는 클래스이기 때문에\n",
    "1. 파라미터를 업데이트하는 함수랑\n",
    "2. 파라미터의 기울기 초기화하는 함수가 담겨.\n",
    "- 옵티마이저 클래스를 정의해두면 학습 루프를 간단하게 짤 수 있어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0496a01-abb6-4a91-ba40-6963000b67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "w,b = linear_model.parameters()\n",
    "\n",
    "#nn.Linear는 모듈이야.\n",
    "#init_params(파라미터 추출) 과 linear1(모델) 작동을 하나로 수행해.\n",
    "#이 클래스 내에 파라미터가 저장돼.\n",
    "#파라미터를 보려면 linear_model.parameters()하면 돼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "734d41ed-1ad0-4dc8-9f1b-79ce5ddcdd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params, self.lr = list(params), lr\n",
    "    \n",
    "    #파라미터를 업데이트하는 함수야.\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "    \n",
    "    #파라미터의 기울기를 초기화하는 함수야.\n",
    "    def zero_grad(self, *args,**kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c621312c-220c-48d2-bceb-b11cd2aa209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78f519e9-c5c8-417c-9f77-20066157b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49320.87840.81980.90820.93260.94530.95510.96340.96580.96680.96870.97070.97310.97510.97560.97650.97750.9780.97850.9785"
     ]
    }
   ],
   "source": [
    "def train_epoch(model) :\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "def train_model(model, epochs) :\n",
    "    for i in range(epochs) :\n",
    "        train_epoch (model)\n",
    "        print (validate_epoch (model), end='')\n",
    "\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f351e2-fa21-4f78-9e45-65949a54c6cc",
   "metadata": {},
   "source": [
    "7단계는 fastai가 제공하는 옵티마이저를 사용하는 거야.\n",
    "- SGD는 BasicOptim과 동일하게 작동해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4170aa20-bb9f-4eda-a3d4-63a42bee9cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49320.88280.8130.90970.93160.94530.95550.96140.96530.96730.96920.97120.97360.97510.97610.97650.97750.9780.97850.9785"
     ]
    }
   ],
   "source": [
    "linear_model = nn. Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18720054-08ac-4081-b5a0-1bd307254053",
   "metadata": {},
   "source": [
    "8단계는 train_model 함수 대신 Learner.fit 으로 학습 시키는 거야.\n",
    "- Learner.fit 을 사용하려면 Learner를 생성해야하고\n",
    "- Learner를 생성하려면 dls를 생성해야해."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7113276f-a127-4a1a-abb3-4a15422d3d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636456</td>\n",
       "      <td>0.503230</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.456453</td>\n",
       "      <td>0.225553</td>\n",
       "      <td>0.801276</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.170107</td>\n",
       "      <td>0.163060</td>\n",
       "      <td>0.855250</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075872</td>\n",
       "      <td>0.099381</td>\n",
       "      <td>0.916094</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041120</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>0.935231</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.051233</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019393</td>\n",
       "      <td>0.045280</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.041053</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3328e7-9af8-4fd7-b9f4-d563b4d7925f",
   "metadata": {},
   "source": [
    "9단계는 모델에 비선형성을 추가하는 거야.\n",
    "- nn.ReLU() 함수가 비선형 모델이야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db87fbe8-56e8-4380-a4c8-9a397f3ea0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.289257</td>\n",
       "      <td>0.413602</td>\n",
       "      <td>0.505397</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077594</td>\n",
       "      <td>0.112413</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051764</td>\n",
       "      <td>0.076591</td>\n",
       "      <td>0.941609</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.060020</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>0.050649</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.044723</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.040660</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025737</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024388</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023289</td>\n",
       "      <td>0.033633</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.030927</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.029869</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.028948</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019776</td>\n",
       "      <td>0.028137</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.027416</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018874</td>\n",
       "      <td>0.026769</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.026185</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.024329</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.023615</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.023298</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>0.022246</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.022027</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.014996</td>\n",
       "      <td>0.021451</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.021283</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.021124</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014438</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1))\n",
    "\n",
    "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a265235-6db1-481d-840e-c27fa1c84693",
   "metadata": {},
   "source": [
    "10단계는 18계층으로 구성된 모델을 학습시키는 거야.\n",
    "- 계층이 아주 깊고, 거의100%에 가까운 정확도를 얻을 수 있어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15abd30e-0ed0-4b46-9b7a-ab4a8c7e71ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064714</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.996565</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
